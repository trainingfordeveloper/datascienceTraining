{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* **300-600 word written report** called  \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gatering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we gather **all** three pieces of data of this project and load them in the notebook. Differents methods are \n",
    "used to gather each data:\n",
    "1. Directly download the WeRateDogs Twitter archive data (twitter_archive_enhanced.csv). Then we upload the data into jupyter notebook and finaly insert into dataframe named **df_twitter_archive_enhanced**.\n",
    "2. Use the Requests library to download the tweet image prediction (image_predictions.tsv). We collect the data from a url address using request library, then transform it to a dataframe named **df_image_predictions**.\n",
    "3. Normaly we use the Tweepy library to query additional data via the Twitter API (tweet_json.txt). However, because of connection failed to the twitter database, we were using direct dowload such as the first method. Then, we fit the data in a dataframe called **df_tweet_json**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After assessing all data, below are some quality and tidiness issues of the three data:\n",
    "\n",
    "### Quality issues\n",
    "\n",
    ">**df_twitter_archive_enhanced** table\n",
    "1. So many **missing values** for in_reply_to_status_id and in_reply_to_user_id attributes, same issues for **retweeted_status_id**, **retweeted_status_user_id** and **retweeted_status_timestamp**\n",
    "2. content of **source** column should be an **url without html anchor**. \n",
    "3. Attributes **timestamp** data type are not a **date** format.\n",
    "4. Some tweet ratings are **not for a dog**.\n",
    "5. Some **duplicated url** for  **expanded_urls** attributes.\n",
    "6. There is **rating_denominator** equal to zero.\n",
    "7. some rating denominator are greatter than 10\n",
    "8.  **text** column contain **text description**  and  **url**. They should be in two separated   columns named **text** and **url**\n",
    "\n",
    ">**image_prediction** table\n",
    "9. some tweet **images** are not a dog \n",
    "\n",
    "\n",
    "\n",
    "### Tidiness issues\n",
    "\n",
    ">**df_twitter_archive_enhanced**\n",
    "1. **doggo, floofer, pupper** and **puppo** columns should be represented by one column named **stage** with datatype **category**\n",
    "\n",
    ">**tweet_json.txt**\n",
    "2.  **tweet_ID** should be **tweet_id** for **tweet_json.txt** and for all tables.\n",
    "\n",
    ">**df_twitter_archive_enhanced, tweet_json, image_prediction**\n",
    "3. The three tables need to be merge in one table by **tweet_id**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this section, we will try to clean all of the issues documented while assessing. \n",
    "First of all, we made a **copy of original data** then check if the copy is successful. Next, we start the cleaning based on the\n",
    "quality issues and tidiness listed above by defining the cleaning action, writting the code and testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning quality issues\n",
    "1. Remove the few rows with non missing values then delete columns.\n",
    "2. Remove anchor < a > ...< /a > for all text in **source** column by creating a function using regular expression then apply to all **source** column values.\n",
    "3. Transform Timestamp data type to date format using pandas **to_datetime** library.\n",
    "4. Remove rows for not a dog rating using pandas **drop** method\n",
    "5. Remove other repetitive url by creating a function using regular expression then apply to all **expanded_urls** column values.\n",
    "6. Replace the rating_numerator with 13 and the rating_denominator 10 where rating_denominator = 0 since 13/10 was the correct rating.\n",
    "7. Normalize the rating numerator and denominator by multiplying with (10 / denominator) for each row.\n",
    "8. Remove rows where tweet images are not a dog\n",
    "9. split text and url in two different columns using regular expression method, a new colums named **url** have been created.\n",
    "\n",
    "\n",
    "#### Cleaning tidiness issues\n",
    "1. we create a new column named 'stage' then fit in all existing values in doggo, floofer, pupper and puppo columns.\n",
    "2. Rename tweet_ID to tweet_id by using pandas **\"rename\"** library\n",
    "3. merge the three tables in one table on **tweet_id**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing DataÂ¶\n",
    "Save gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to html\n",
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'wrangle_report.ipynb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
